移学习中的常见技巧:_微调_（fine-tuning），微调包括以下四个步骤。
1. 在源数据集（例如ImageNet数据集）上预训练神经网络模型，即**源模型**。
2. 创建一个新的神经网络模型，即**目标模型**。这将复制源模型上的所有模型设计及其参数（输出层除外）。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。
3. 向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。
4. 在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。

![[Pasted image 20231118141050.png|588]](../images/20231118141050.png)

最先起源于计算机视觉，多应用于[[残差神经网络（ResNet）]]的调优。

- 意料之中，微调模型往往表现更好，因为它的初始参数值更有效。
- 迁移学习将从源数据集中学到的知识**迁移**到目标数据集，微调是迁移学习的常见技巧。
- 除输出层外，目标模型从源模型中复制所有模型设计及其参数，并根据目标数据集对这些参数进行微调。但是，目标模型的输出层需要从头开始训练。
- 通常，微调参数使用较小的学习率，而从头开始训练输出层可以使用更大的学习率。