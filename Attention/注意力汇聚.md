查询(Query)和键(Key)交互形成了注意力汇聚，从而有倾向的选择了值(Value)作为输入以生成输出。

## 平均汇聚
平均汇聚意味着不对Key进行选择，当查询时，直接返回平均环境信息计算的值。

$f(x) = {1 \over n}{\sum{y_i}}$

## 非参数注意力汇聚
平均汇聚相当于没有使用汇聚，Nadaraya和watson提出根据输入的位置对输出 $y_i$ 进行加权。

$f(x) = {\sum^n_{i=1}} {K(x-x_i) \over \sum^n_{j=1} K(x-x_j)}y_i$

其中 $K$ 是核(kernel)。因此受此启发，可以写出更加通用的注意力公式:

$f(x)=\sum^n_{i=1}\alpha(x_i,x)y_i$

其中 $x$ 是查询， $(x_i,y_i)$ 是键值对,注意力汇聚是 $y_i$ 的加权平均。将查询 $x$ 和键 $(x_i,y_i)$ 之间的关系建模为 **注意力权重（attention weight）** $\alpha(x,x_i)$ 。

如果使用高斯核则:

$K(u) = \frac{1}{\sqrt{2\pi}} \exp(-\frac{u^2}{2}).$

$\begin{split}\begin{aligned} f(x) &=\sum_{i=1}^n \alpha(x, x_i) y_i\\ &= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}(x - x_i)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}(x - x_j)^2\right)} y_i \\&= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}(x - x_i)^2\right) y_i. \end{aligned}\end{split}$

但是这里没有可以选择的参数。

## 参数化注意力汇聚
在之前的基础上引入可以学习的参数 $w$ 。

$f(x)= \sum^n_{i=1}softmax(-{1\over 2}((x-x_i)w_i)^2)y_i$

