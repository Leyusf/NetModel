随着神经网络深度的增加，梯度消失的现象越加频繁。何恺明等人提出了残差网络。残差网络的核心思想是：每个附加层都应该更容易地包含原始函数作为其元素之一。

## 残差块
左侧是正常块，右侧是残差块。
![[Pasted image 20231118135646.png|448]](../images/20231118135646.png)
两种不同的残差块：
![[Pasted image 20231118135742.png|575]](../images/20231118135742.png)

## ResNet模型
ReNet的前两层跟之前介绍的[[含并行连结的网络（GoogLeNet）]]中的一样： 在输出通道数为64、步幅为2的7×7卷积层后，接步幅为2的3×3的最大汇聚层。 不同之处在于ResNet每个卷积层后增加了批量规范化层。
![[Pasted image 20231118135825.png|326]](../images/20231118135825.png)