# 经典的模型结构
该仓库实现了经典的卷积神经网络和循环神经网络以及注意力机制的经典模型的pytorch实现。

# 运行各个模块示例
```
# python runner.py 目录 运行的文件(xxx_train_test.py)
python runner.py LeNet lenet_train_test.py
```

## 卷积神经网络
- [LeNet](LeNet/LeNet.md)
- [AlexNet](AlexNet/AlexNet.md)
- [VGG](VGG/使用块的网络(VGG).md)
- [NiN](NiN/网格中的网络（NiN）.md)
- [GoogLeNet](GoogLeNet/含并行连结的网络（GoogLeNet）.md)
- [ResNet](ResNet/残差神经网络（ResNet）.md)
- [DenseNet](DenseNet/稠密连接网络（DenseNet）.md)
- [微调] (FineTuning/微调.md)

## 循环神经网络
- [n-grams与数据集](NGrams/n-grams与数据集.md)
- [Seq2Seq](SequenceModel/Seq2Seq.md)
- [编码器-解码器](RNN/编码器-解码器.md)
- [RNN](RNN/循环神经网络(RNN).md)
- [双向RNN](RNN/双向循环神经网络.md)
- [深度RNN](RNN/深度循环神经网络.md)
- [GRU](RNN/门控循环单元(GRU).md)
- [LSTM](RNN/长短期记忆网络(LSTM).md)
- [文本预处理](RNN/文本预处理.md)
- [束搜索](RNN/束搜索.md)

## 注意力机制
- [注意力机制] (Attention/注意力机制.md)
- [注意力分数](Attention/注意力分数.md)
- [注意力汇聚](Attention/注意力汇聚.md)
- [使用注意力机制的Seq2Seq] (Attention/使用注意力机制的Seq2Seq.md)
- [多头注意力机制](Attention/多头注意力机制.md)
- [自注意力和位置编码](Attention/自注意力和位置编码.md)
- [Transformer](Attention/Transformer.md)
- [BERT](Attention/BERT.md)



