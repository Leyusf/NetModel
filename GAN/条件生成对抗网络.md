Conditional GAN (CGAN，条件GAN)，是 Mehdi Mirza于2014年11月份发表的一篇文章，也是 GAN 系列的早期经典模型之一，是目前许多GAN应用的前身。原始GAN的缺点：生成的图像是随机的，不可预测的，无法控制网络输出特定的图片，生成目标不明确，可控性不强针对原始GAN不能生成具有特定属性的图片的问题，Mehdi Mirza等人提出了cGAN，其核心在于将属性信息y融入生成器G和判别器D中，属性y可以是任何标签信息，例如图像的类别、人脸图像的面部表情等。

CGAN的中心思想是希望可以**控制 GAN 生成的图片**，而不是单纯的随机生成图片。具体来说，Conditional GAN 在生成器和判别器的输入中增加了额外的 条件信息，生成器生成的图片只有足够真实且与条件相符，才能够通过判别器。

## 原理

$$
\min_G \max_D V(G, D) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x|y)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z|y)))]
$$

为了实现条件GAN的目的，生成网络和判别网络的原理和训练方式均要有所改变。模型部分，在判别器和生成器中都添加了额外信息 y，y 可以是类别标签或者是其他类型的数据，可以将 y 作为一个额外的输入层丢入判别器和生成器。在生成器中，作者将输入噪声 z 和 y 连在一起隐含表示，带条件约束这个简单直接的改进被证明非常有效,并广泛用于后续的相关工作中。论文是在MNIST数据集上以类别标签为条件变量，生成指定类别的图像。作者还探索了CGAN在用于图像自动标注的多模态学习上的应用，在MIR Flickr25000数据集上，以图像特征为条件变量，生成该图像的tag的词向量。
![[Pasted image 20231210180948.png|410]](./images/20231210180948.png)
CGAN生成的图像虽有很多缺陷，譬如图像边缘模糊，生成的图像分辨率太低等，但是它为后面的pix2pixGAN和Cycle-GAN开拓了道路，这两个模型转换图像风格时对属性特征的处理方法均受cGAN启发。
